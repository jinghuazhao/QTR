## Comparison of P values from linear and linear mixed models

This is illustrated with the documentation example.

```{r}
require(lme4)
boxplot(Reaction~Days, data=sleepstudy, main="Reaction by Days",
        xlab="Days", ylab="Reaction", col="blue", border="black")
```
We see a trend of `Reaction` by `Days`, so it is reasonable to fit a simple linear regression,
```{r}
l <- lm(Reaction ~ Days, sleepstudy)
s <- summary(l)
s
names(s)
class(s)
round(sqrt(s$fstatistic[1]),3)
```
the F statistics is simply $t^2$. Maybe it is worthwhile to examine the effect of `Subject` as well; from

```{r}
boxplot(Reaction~Subject, data=sleepstudy, main="Reaction by Subject",
        xlab="Subject", ylab="Reaction", col="orange", border="brown")
```
it is more approriate to fit a random effect model
```{r}
f <- lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
s <- summary(f)
s
names(s)
class(with(s,coefficients))
t <- with(s,coefficients)[,3]
p <- 2*(pnorm(-abs(t)))
p
```
Consequently, the effect of `Days` on `Reaction` became less pronounced after accounting for individual differences -- as
we saw the same estimate of effect but a larger standard error for `Days` in the linear mixed model compared to that in the linear regression model.
