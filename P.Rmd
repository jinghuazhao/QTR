## Comparison of P values from linear and linear mixed models

This is provided by the `lmerTest` package as illustrated fully with the documentation example here.
```{r}
require(lmerTest)
boxplot(Reaction~Days, data=sleepstudy, main="Reaction by Days",
        xlab="Days", ylab="Reaction", col="blue", border="black")
```
We see a trend of `Reaction` by `Days`, so it is reasonable to fit a simple linear regression,
```{r}
l <- lm(Reaction ~ Days, sleepstudy)
s <- summary(l)
s
names(s)
```
Now the `Subject` effect is treated as a random; from

```{r}
boxplot(Reaction~Subject, data=sleepstudy, main="Reaction by Subject",
        xlab="Subject", ylab="Reaction", col="orange", border="brown")
```
it is more approriate to fit a random effect model
```{r}
f <- lme4::lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
s <- summary(f)
s
names(s)
```
We saw the same estimate of effect but a larger standard error for `Days` in the linear mixed model compared to that in the linear regression model.

```{r}
m <- lmerTest::lmer(Reaction ~ Days + (Days | Subject), sleepstudy)
class(m)
s <-summary(m)
names(s)
with(s,coefficients)[,5]
```
